{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv (r'C:\\Afif\\SEM4\\Data Analytics\\train.csv')   \n",
    "test = pd.read_csv (r'C:\\Afif\\SEM4\\Data Analytics\\test.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of              id                                          url_legal  \\\n",
       "0     c12129c31                                                NaN   \n",
       "1     85aa80a4c                                                NaN   \n",
       "2     b69ac6792                                                NaN   \n",
       "3     dd1000b26                                                NaN   \n",
       "4     37c1b32fb                                                NaN   \n",
       "...         ...                                                ...   \n",
       "2829  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n",
       "2830  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2831  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2832  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n",
       "2833  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n",
       "\n",
       "           license                                            excerpt  \\\n",
       "0              NaN  When the young people returned to the ballroom...   \n",
       "1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n",
       "2              NaN  As Roger had predicted, the snow departed as q...   \n",
       "3              NaN  And outside before the palace a great garden w...   \n",
       "4              NaN  Once upon a time there were Three Bears who li...   \n",
       "...            ...                                                ...   \n",
       "2829  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n",
       "2830  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n",
       "2831  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n",
       "2832  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n",
       "2833  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n",
       "\n",
       "        target  standard_error  \n",
       "0    -0.340259        0.464009  \n",
       "1    -0.315372        0.480805  \n",
       "2    -0.580118        0.476676  \n",
       "3    -1.054013        0.450007  \n",
       "4     0.247197        0.510845  \n",
       "...        ...             ...  \n",
       "2829  1.711390        0.646900  \n",
       "2830  0.189476        0.535648  \n",
       "2831  0.255209        0.483866  \n",
       "2832 -0.215279        0.514128  \n",
       "2833  0.300779        0.512379  \n",
       "\n",
       "[2834 rows x 6 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2834, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                False\n",
       "url_legal          True\n",
       "license            True\n",
       "excerpt           False\n",
       "target            False\n",
       "standard_error    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# return the wordnet object value corresponding to the POS tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    \n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)\n",
    "\n",
    "# clean text data\n",
    "train['clean_text'] = train['excerpt'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>young people return ballroom present decidedly...</td>\n",
       "      <td>-0.340259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dinner time mrs fayre somewhat silent eye rest...</td>\n",
       "      <td>-0.315372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roger predict snow departed quickly come two d...</td>\n",
       "      <td>-0.580118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text    target\n",
       "0  young people return ballroom present decidedly... -0.340259\n",
       "1  dinner time mrs fayre somewhat silent eye rest... -0.315372\n",
       "2  roger predict snow departed quickly come two d... -0.580118"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select 2 columns\n",
    "df = train[['clean_text','target']]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX= df['clean_text']\n",
    "dfY=df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer for Pipeline (Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7115"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(dfX)\n",
    "X_train_vectorized = vect.transform(dfX)\n",
    "len(vect.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(X_train_vectorized)\n",
    "\n",
    "tfidf_matrix =  tfidf_transformer.fit_transform(X_train_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X2, val_X2, train_y2, val_y2 = train_test_split(tfidf_matrix, dfY, test_size = 0.3, random_state=71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_X2, train_y2)\n",
    "lgb_eval = lgb.Dataset(val_X2, val_y2, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0 : LGB Model with same parameters in baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 31813\n",
      "[LightGBM] [Info] Number of data points in the train set: 1983, number of used features: 1364\n",
      "[LightGBM] [Info] Start training from score -0.946486\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\tvalid_0's rmse: 0.821454\n",
      "[200]\tvalid_0's rmse: 0.830269\n",
      "[300]\tvalid_0's rmse: 0.834782\n",
      "[400]\tvalid_0's rmse: 0.837365\n",
      "[500]\tvalid_0's rmse: 0.838521\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's rmse: 0.819103\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'regression',   # 回帰問題\n",
    "    'metric': 'rmse',            # RMSEで評価\n",
    "}\n",
    "lgbModel = lgb.train(params, lgb_train, valid_sets=lgb_eval,\n",
    "                     verbose_eval=100,  # 50イテレーション毎に学習結果出力\n",
    "                     num_boost_round=1000,  # 最大イテレーション回数指定\n",
    "                     early_stopping_rounds=500,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : LGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.824240571071137"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgModel2 = lgb.LGBMRegressor().fit(train_X2, train_y2)\n",
    "y_pred = lgModel2.predict(val_X2)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(val_y2, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 : Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9244243751849708"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel = LinearRegression().fit(train_X2, train_y2)\n",
    "y_pred = lrModel.predict(val_X2)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(val_y2, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 : Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(train_X2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7596590967572867"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = ridge.predict(val_X2)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(val_y2, y_pred2))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2227667016879396"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtModel = DecisionTreeRegressor().fit(train_X2, train_y2)\n",
    "y_pred = dtModel.predict(val_X2)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(val_y2, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5 : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_rf = RandomForestRegressor()\n",
    "model_rf.fit(train_X2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8569939115230927"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = model_rf.predict(val_X2)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(val_y2, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'alpha': 1.0,\n",
      " 'copy_X': True,\n",
      " 'fit_intercept': True,\n",
      " 'max_iter': None,\n",
      " 'normalize': False,\n",
      " 'random_state': None,\n",
      " 'solver': 'auto',\n",
      " 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "ridge_tuning = Ridge()\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(ridge_tuning.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 1.0, 1.3, 1.5],\n",
      " 'fit_intercept': [True, False],\n",
      " 'max_iter': [50, 100, 300, 500, 700, 1000, None],\n",
      " 'normalize': [True, False],\n",
      " 'solver': ['auto', 'sparse_cg']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# alpha : range\n",
    "alpha = [0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 1.0, 1.3, 1.5]\n",
    "\n",
    "\n",
    "# fit_intercept\n",
    "fit_intercept = [True , False]\n",
    "\n",
    "\n",
    "# max_iter\n",
    "max_iter = [50, 100, 300, 500, 700, 1000, None]\n",
    "\n",
    "\n",
    "# normalize\n",
    "normalize = [True , False]\n",
    "\n",
    "# solver\n",
    "solver = ['auto','sparse_cg']\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'alpha': alpha,  \n",
    "               'fit_intercept': fit_intercept,\n",
    "               'max_iter': max_iter,\n",
    "               'normalize': normalize,\n",
    "               'solver': solver}\n",
    "\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=Ridge(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.001, 0.01, 0.1, 0.3, 0.5,\n",
       "                                                  0.7, 1.0, 1.3, 1.5],\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'max_iter': [50, 100, 300, 500, 700,\n",
       "                                                     1000, None],\n",
       "                                        'normalize': [True, False],\n",
       "                                        'solver': ['auto', 'sparse_cg']},\n",
       "                   random_state=42, scoring='neg_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "r_random = RandomizedSearchCV(estimator = ridge_tuning, param_distributions = random_grid, scoring=\"neg_mean_squared_error\", n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "r_random.fit(train_X2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'auto',\n",
       " 'normalize': False,\n",
       " 'max_iter': 1000,\n",
       " 'fit_intercept': True,\n",
       " 'alpha': 1.0}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'solver': 'auto',\n",
    " 'normalize': True,\n",
    " 'max_iter': 500,\n",
    " 'fit_intercept': True,\n",
    " 'alpha': 2.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'solver': 'auto',\n",
    " 'normalize': False,\n",
    " 'max_iter': 1000,\n",
    " 'fit_intercept': True,\n",
    " 'alpha': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Base:  0.7596590967572867\n",
      "RMSE Random:  0.7567051108744559\n",
      "Improvement of 0.39%.\n"
     ]
    }
   ],
   "source": [
    "base_model = Ridge(random_state = 42)\n",
    "base_model.fit(train_X2,train_y2)\n",
    "pred_base = base_model.predict(val_X2)\n",
    "rmse_base = np.sqrt(metrics.mean_squared_error(val_y2, pred_base))\n",
    "print(\"RMSE Base: \",rmse_base)\n",
    "\n",
    "best_random = Ridge(alpha = 2.5, solver = 'auto', normalize = True, max_iter = 500, fit_intercept = True, random_state = 42)\n",
    "best_random.fit(train_X2,train_y2)\n",
    "pred_random = best_random.predict(val_X2)\n",
    "rmse_random = np.sqrt(metrics.mean_squared_error(val_y2, pred_random))\n",
    "print(\"RMSE Random: \",rmse_random)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (rmse_base - rmse_random) / rmse_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 1.0, 1.3, 1.5, 2.5, 5.0, 10],\n",
      " 'fit_intercept': [True, False],\n",
      " 'max_iter': [50, 100, 300, 500, 700, 1000, None],\n",
      " 'normalize': [True, False],\n",
      " 'solver': ['auto', 'sparse_cg']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# alpha : range\n",
    "alpha = [0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 1.0, 1.3, 1.5,2.5,5.0,10]\n",
    "\n",
    "\n",
    "# fit_intercept\n",
    "fit_intercept = [True , False]\n",
    "\n",
    "\n",
    "# max_iter\n",
    "max_iter = [50, 100, 300, 500, 700, 1000, None]\n",
    "\n",
    "\n",
    "# normalize\n",
    "normalize = [True , False]\n",
    "\n",
    "# solver\n",
    "solver = ['auto','sparse_cg']\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "search_grid = {'alpha': alpha,\n",
    "               'fit_intercept': fit_intercept,\n",
    "               'max_iter': max_iter,\n",
    "               'normalize': normalize,\n",
    "               'solver': solver}\n",
    "\n",
    "\n",
    "pprint(search_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 672 candidates, totalling 2016 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 634 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1744 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2016 out of 2016 | elapsed:   16.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Ridge(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 1.0, 1.3,\n",
       "                                   1.5, 2.5, 5.0, 10],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'max_iter': [50, 100, 300, 500, 700, 1000, None],\n",
       "                         'normalize': [True, False],\n",
       "                         'solver': ['auto', 'sparse_cg']},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "r_grid = GridSearchCV(estimator = ridge_tuning, param_grid = search_grid, scoring=\"neg_mean_squared_error\", cv = 3, verbose=2,  n_jobs = -1)\n",
    "# Fit the random search model\n",
    "r_grid.fit(train_X2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 2.5,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 50,\n",
       " 'normalize': True,\n",
       " 'solver': 'auto'}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Base:  0.7596590967572867\n",
      "RMSE Grid:  0.7567051108744559\n",
      "Improvement of 0.39%.\n"
     ]
    }
   ],
   "source": [
    "base_model = Ridge(random_state = 42)\n",
    "base_model.fit(train_X2,train_y2)\n",
    "pred_base = base_model.predict(val_X2)\n",
    "rmse_base = np.sqrt(metrics.mean_squared_error(val_y2, pred_base))\n",
    "print(\"RMSE Base: \",rmse_base)\n",
    "\n",
    "best_grid = Ridge(alpha = 2.5, solver = 'auto', normalize = True, max_iter = 50, fit_intercept = True, random_state = 42)\n",
    "best_grid.fit(train_X2,train_y2)\n",
    "pred_grid = best_grid.predict(val_X2)\n",
    "rmse_grid = np.sqrt(metrics.mean_squared_error(val_y2, pred_grid))\n",
    "print(\"RMSE Grid: \",rmse_grid)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (rmse_base - rmse_grid) / rmse_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH CV LEVEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [2.3, 2.4, 2.5, 2.6],\n",
      " 'fit_intercept': [True, False],\n",
      " 'max_iter': [50, 60, 70, None],\n",
      " 'normalize': [True, False],\n",
      " 'solver': ['auto', 'sparse_cg']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# alpha : range\n",
    "alpha = [2.3,2.4,2.5,2.6]\n",
    "\n",
    "\n",
    "# fit_intercept\n",
    "fit_intercept = [True , False]\n",
    "\n",
    "\n",
    "# max_iter\n",
    "max_iter = [50,60,70 , None]\n",
    "\n",
    "\n",
    "# normalize\n",
    "normalize = [True , False]\n",
    "\n",
    "# solver\n",
    "solver = ['auto','sparse_cg']\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "search_grid = {'alpha': alpha,\n",
    "               'fit_intercept': fit_intercept,\n",
    "               'max_iter': max_iter,\n",
    "               'normalize': normalize,\n",
    "               'solver': solver}\n",
    "\n",
    "\n",
    "pprint(search_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Ridge(), n_jobs=-1,\n",
       "             param_grid={'alpha': [2.3, 2.4, 2.5, 2.6],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'max_iter': [50, 60, 70, None],\n",
       "                         'normalize': [True, False],\n",
       "                         'solver': ['auto', 'sparse_cg']},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "r_grid = GridSearchCV(estimator = ridge_tuning, param_grid = search_grid, scoring=\"neg_mean_squared_error\", cv = 3, verbose=2,  n_jobs = -1)\n",
    "# Fit the random search model\n",
    "r_grid.fit(train_X2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 2.6,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 50,\n",
       " 'normalize': True,\n",
       " 'solver': 'auto'}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Base:  0.7596590967572867\n",
      "RMSE Grid:  0.7568998143139294\n",
      "Improvement of 0.36%.\n"
     ]
    }
   ],
   "source": [
    "base_model = Ridge(random_state = 42)\n",
    "base_model.fit(train_X2,train_y2)\n",
    "pred_base = base_model.predict(val_X2)\n",
    "rmse_base = np.sqrt(metrics.mean_squared_error(val_y2, pred_base))\n",
    "print(\"RMSE Base: \",rmse_base)\n",
    "\n",
    "best_grid = Ridge(alpha = 2.6, solver = 'auto', normalize = True, max_iter = 50, fit_intercept = True, random_state = 42)\n",
    "best_grid.fit(train_X2,train_y2)\n",
    "pred_grid = best_grid.predict(val_X2)\n",
    "rmse_grid = np.sqrt(metrics.mean_squared_error(val_y2, pred_grid))\n",
    "print(\"RMSE Grid: \",rmse_grid)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (rmse_base - rmse_grid) / rmse_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
